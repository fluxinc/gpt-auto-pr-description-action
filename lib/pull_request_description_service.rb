# lib/pull_request_description_service.rb
require 'octokit'
require 'openai'
require 'net/http'
require 'uri'

module PullRequestDescriptionService
  class Generator
    EXCLUDED_DIRECTORIES = ['node_modules', 'vendor'].freeze

    def initialize(repo, pr_number, github_repository, trigger, pull_request_template = nil)
      @repo = repo
      @pr_number = pr_number
      @github_repository = github_repository
      @trigger = trigger
      @pull_request_template = pull_request_template

      # Instantiate Octokit and OpenAI clients with provided tokens
      @client = Octokit::Client.new(access_token: ENV['GITHUB_TOKEN'])
      @openai_client = OpenAI::Client.new(access_token: ENV['OPENAI_TOKEN'])
    end

    # Runs the PR description generation process
    # @return [String] the PR description generated by OpenAI
    def run
      if check_trigger
        update_pull_request
      else
        puts "Trigger not found in PR description, skipping"
      end
    end

    # Generates the PR description based on commits and diff
    # @return [String] the generated PR description
    def generate_prompt
      # If the pull_request_template.md file is set, read its contents
      template_markdown = if @pull_request_template != ""
        File.read("templates/#{@pull_request_template}")
      else
        "Give a description of the changes in a list of this PR."
      end

      commits = get_commits_from_pull_request
      git_diff = get_diff

      commit_list = commits.map { |commit| "- #{commit}" }.join("\n")
      prompt = <<~PROMPT
        I have a feature with the following commits:

        #{commit_list}

        I have the following diff:

        #{git_diff}

        Write a Pull Request description for this diff in this format:

        ```md
        #{template_markdown}
        ```

        Give PR description using the format above, remove sections that are not relevant to the diff.
      PROMPT

      puts "Prompt: #{prompt}"

      response = @openai_client.chat(
        parameters: {
          # model: "gpt-3.5-turbo-16k", # Required.
          # model: "gpt-4-32k-0613",
          model: ENV.fetch('OPENAI_MODEL', 'gpt-3.5-turbo-16k'),
          messages: [
            {role: "system", content: "You are a helpful assistant that's going to help write a PR description."},
            {role: "user", content: prompt}
          ],
          temperature: 0.7,
          max_tokens: 1600,
        }
      )
      puts "Response: #{response}"

      response['choices'].first['message']['content'].strip
    end

    # @return [Array] an array of commit messages
    def get_commits_from_pull_request
      @client.pull_request_commits(@repo, @pr_number).map { |commit| commit[:commit][:message] }
    end

    # @return [String] concatenated diff hunks
    def get_diff
      diff = @client.pull_request(@github_repository, @pr_number, accept: 'application/vnd.github.VERSION.diff')
      token_count = count_tokens(diff)

      # Cut the string down to the maximum length if it's too long
      if token_count > 12000
        diff = diff[0..(12000*4)] + '... [Diff truncated due to length]'
      end

      puts "Diff: #{diff}"
      diff
    end

    # https://help.openai.com/en/articles/4936856-what-are-tokens-and-how-to-count-them
    def count_tokens(text)
      text.length / 4
    end

    def check_trigger
      return true if  @trigger == ""
      return true if @client.pull_request(@github_repository, @pr_number).body.include?(@trigger)

      false
    end

    # Updates the PR description on GitHub
    def update_pull_request
      description = generate_prompt
      @client.update_pull_request(@github_repository, @pr_number, body: description)
    end
  end
end
